{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c27c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db96d043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import imageio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy import linalg\n",
    "import numpy as np\n",
    "\n",
    "from kaiwu.classical import SimulatedAnnealingOptimizer\n",
    "from model import Generator, Discriminator, QGAN\n",
    "from utils import show_result, show_train_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8885e617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "batch_size = 128\n",
    "lr = 0.0002\n",
    "train_epoch = 100\n",
    "num_visible = 256\n",
    "num_hidden = 100\n",
    "\n",
    "# results save folder\n",
    "save_path = './MNIST_QGAN_results/'\n",
    "if not os.path.isdir(f'{save_path}'):\n",
    "    os.mkdir(f'{save_path}')\n",
    "if not os.path.isdir(f'{save_path}/Random_results'):\n",
    "    os.mkdir(f'{save_path}/Random_results')\n",
    "if not os.path.isdir(f'{save_path}/Fixed_results'):\n",
    "    os.mkdir(f'{save_path}/Fixed_results')\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "fixed_z_ = torch.randn((5 * 5, 100)).to(device)  # fixed noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03650786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5,), std=(0.5,))  # MNIST是单通道\n",
    "])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True, transform=transform),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# network\n",
    "G = Generator(input_size=100, n_class=28*28).to(device)\n",
    "D = Discriminator(input_size=28*28, n_class=1).to(device)\n",
    "sampler = SimulatedAnnealingOptimizer(initial_temperature=1e4, cutoff_temperature=1e2,\n",
    "                                        alpha=0.9, size_limit=batch_size)\n",
    "qgan = QGAN(G, D, sampler, num_visible, num_hidden).to(device)\n",
    "\n",
    "# Binary Cross Entropy loss\n",
    "BCE_loss = nn.BCELoss()\n",
    "\n",
    "# Adam optimizer\n",
    "G_optimizer = optim.Adam(G.parameters(), lr=lr)\n",
    "D_optimizer = optim.Adam(D.parameters(), lr=lr)\n",
    "rbm_optimizer = optim.Adam(qgan.bm.parameters(), lr=lr*0.1)\n",
    "\n",
    "train_hist = {}\n",
    "train_hist['D_losses'] = []\n",
    "train_hist['G_losses'] = []\n",
    "\n",
    "print(\"Training start!\")\n",
    "for epoch in range(train_epoch):\n",
    "    D_losses = []\n",
    "    G_losses = []\n",
    "    rbm_losses = []\n",
    "\n",
    "    for x_, _ in tqdm(train_loader):\n",
    "        # train discriminator D\n",
    "        # ============================================================\n",
    "        D_optimizer.zero_grad()\n",
    "        x_ = x_.view(-1, 28 * 28).to(device)\n",
    "        d_loss = qgan.d_loss(x_)\n",
    "        d_loss.backward()\n",
    "        D_optimizer.step()\n",
    "        D_losses.append(d_loss.item())\n",
    "\n",
    "        # train generator G\n",
    "        # ============================================================\n",
    "        G_optimizer.zero_grad()\n",
    "        g_loss = qgan.g_loss()\n",
    "        g_loss.backward()\n",
    "        G_optimizer.step()\n",
    "        G_losses.append(g_loss.item())\n",
    "\n",
    "        # train RBM\n",
    "        # ============================================================\n",
    "        rbm_optimizer.zero_grad()\n",
    "        binarized_features  = D.get_feature(x_).detach() # 提取真实图像的特征且不更新鉴别器梯度\n",
    "        rbm_loss = qgan.rbm_loss(binarized_features)\n",
    "        rbm_loss.backward()\n",
    "        rbm_optimizer.step()\n",
    "        rbm_losses.append(rbm_loss.item())\n",
    "\n",
    "    print('[%d/%d]: loss_d: %.3f, loss_g: %.3f, loss_rbm: %3.f' % (\n",
    "        (epoch + 1), train_epoch, \n",
    "        torch.mean(torch.FloatTensor(D_losses)), \n",
    "        torch.mean(torch.FloatTensor(G_losses)),\n",
    "        torch.mean(torch.FloatTensor(rbm_losses)))\n",
    "    )\n",
    "    \n",
    "    p = f'{save_path}/Random_results/MNIST_GAN_' + str(epoch + 1) + '.png'\n",
    "    fixed_p = f'{save_path}/Fixed_results/MNIST_GAN_' + str(epoch + 1) + '.png'\n",
    "    show_result(qgan, (epoch+1), save=True, path=p)\n",
    "    show_result(qgan, (epoch+1), save=True, path=fixed_p)\n",
    "    train_hist['D_losses'].append(torch.mean(torch.FloatTensor(D_losses)).item())\n",
    "    train_hist['G_losses'].append(torch.mean(torch.FloatTensor(G_losses)).item())\n",
    "\n",
    "print(\"Training finish!... save training results\")\n",
    "torch.save(G.state_dict(), f\"{save_path}/generator_param.pkl\")\n",
    "torch.save(D.state_dict(), f\"{save_path}/discriminator_param.pkl\")\n",
    "with open(f'{save_path}/train_hist.pkl', 'wb') as f:\n",
    "    pickle.dump(train_hist, f)\n",
    "\n",
    "show_train_hist(train_hist, save=True, path=f'{save_path}/MNIST_GAN_train_hist.png')\n",
    "\n",
    "images = []\n",
    "for e in range(train_epoch):\n",
    "    img_name = f'{save_path}/Fixed_results/MNIST_GAN_' + str(e + 1) + '.png'\n",
    "    images.append(imageio.imread(img_name))\n",
    "imageio.mimsave(f'{save_path}/generation_animation.gif', images, fps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075e833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fid(real_features, fake_features):\n",
    "    \"\"\"\n",
    "    计算 Fréchet Inception Distance (FID)。\n",
    "    real_features: [N, d] 真实样本特征\n",
    "    fake_features: [N, d] 生成样本特征\n",
    "    \"\"\"\n",
    "    mu1 = np.mean(real_features, axis=0)\n",
    "    mu2 = np.mean(fake_features, axis=0)\n",
    "    sigma1 = np.cov(real_features, rowvar=False)\n",
    "    sigma2 = np.cov(fake_features, rowvar=False)\n",
    "\n",
    "    ssdiff = mu1 - mu2\n",
    "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    if not np.isfinite(covmean).all():\n",
    "        covmean = linalg.sqrtm(sigma1.dot(sigma2) + 1e-6 * np.eye(sigma1.shape[0]))\n",
    "\n",
    "    fid = ssdiff.dot(ssdiff) + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    return fid.real\n",
    "\n",
    "def compute_fid_score(G, D, dataloader, device, num_samples=10000, z_dim=100):\n",
    "    \"\"\"\n",
    "    使用判别器 D 提取特征，计算 GAN 生成图像与真实图像之间的 FID。\n",
    "    \"\"\"\n",
    "    G.eval()\n",
    "    D.eval()\n",
    "\n",
    "    real_feats = []\n",
    "    fake_feats = []\n",
    "\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        # 收集真实图像特征\n",
    "        for x, _ in tqdm(dataloader, desc=\"Extracting real features\"):\n",
    "            x = x.view(x.size(0), -1).to(device)\n",
    "            feat = D.get_feature(x).cpu().numpy()  # 假设 get_feature 返回 flatten 特征\n",
    "            real_feats.append(feat)\n",
    "            total += x.size(0)\n",
    "            if total >= num_samples:\n",
    "                break\n",
    "    real_feats = np.concatenate(real_feats, axis=0)[:num_samples]\n",
    "\n",
    "    # 生成假图像并提取特征\n",
    "    total = 0\n",
    "    while total < num_samples:\n",
    "        z = torch.randn(min(num_samples - total, 1000), z_dim).to(device)\n",
    "        fake_imgs = G(z).detach()\n",
    "        feat = D.get_feature(fake_imgs).detach().cpu().numpy()\n",
    "        fake_feats.append(feat)\n",
    "        total += feat.shape[0]\n",
    "    fake_feats = np.concatenate(fake_feats, axis=0)[:num_samples]\n",
    "\n",
    "    fid = calculate_fid(real_feats, fake_feats)\n",
    "    return fid\n",
    "\n",
    "fid_score = compute_fid_score(G, D, train_loader, device, num_samples=5000)\n",
    "print(f\"FID Score: {fid_score:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
