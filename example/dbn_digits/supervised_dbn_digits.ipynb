{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dd5ac77",
   "metadata": {},
   "source": [
    "### 堆叠受限玻尔兹曼机（RBM）原理与代码实现总结\n",
    "---\n",
    "#### **一、RBM原理概述**\n",
    "受限玻尔兹曼机（Restricted Boltzmann Machine）是一种基于能量的概率图模型，由可见层（Visible Layer）和隐层（Hidden Layer）组成，层内无连接，层间全连接。其核心是通过无监督学习学习数据的潜在特征分布。\n",
    "##### **1. 模型结构**\n",
    "- **可见层（v）**：输入数据的显式表示（如像素值）。\n",
    "- **隐层（h）**：提取的潜在特征。\n",
    "- **权重矩阵（W）**：连接可见层与隐层的权重。\n",
    "- **偏置**：可见层偏置（b）和隐层偏置（c）。\n",
    "##### **2. 能量函数与概率分布**\n",
    "RBM的能量函数定义为：\n",
    "$$\n",
    "E(\\mathbf{v}, \\mathbf{h}) = -\\mathbf{v}^T W \\mathbf{h} - \\mathbf{b}^T \\mathbf{v} - \\mathbf{c}^T \\mathbf{h}\n",
    "$$\n",
    "联合概率分布通过玻尔兹曼分布给出：\n",
    "$$\n",
    "P(\\mathbf{v}, \\mathbf{h}) = \\frac{ e^{-E(\\mathbf{v}, \\mathbf{h})} }{Z}\n",
    "$$\n",
    "其中 $ Z $ 为配分函数（归一化因子）。可见层的边缘分布为：\n",
    "$$\n",
    "P(\\mathbf{v}) = \\sum_{\\mathbf{h}} P(\\mathbf{v}, \\mathbf{h})\n",
    "$$\n",
    "##### **3. 条件独立性**\n",
    "由于层内无连接，给定可见层时隐层条件独立，反之亦然：\n",
    "$$\n",
    "P(h_j=1|\\mathbf{v}) = \\sigma\\left(\\sum_i W_{ij} v_i + c_j\\right)\n",
    "$$\n",
    "$$\n",
    "P(v_i=1|\\mathbf{h}) = \\sigma\\left(\\sum_j W_{ij} h_j + b_i\\right)\n",
    "$$\n",
    "其中 $\\sigma(x) = \\frac{1}{1+e^{-x}}$ 为Sigmoid激活函数。\n",
    "##### **4. 训练目标**\n",
    "通过最大化似然函数学习参数（W, b, c）。目标函数为负对数似然：\n",
    "$$\n",
    "\\mathcal{L} = -\\sum_{\\mathbf{v}} \\log P(\\mathbf{v})\n",
    "$$\n",
    "采用对比散度（CD）算法近似梯度，更新规则为：\n",
    "$$\n",
    "\\Delta W_{ij} = \\epsilon \\left(\\langle v_i h_j \\rangle_{\\text{data}} - \\langle v_i h_j \\rangle_{\\text{recon}}\\right)\n",
    "$$\n",
    "其中 $\\epsilon$ 为学习率，$\\langle \\cdot \\rangle_{\\text{data}}$ 和 $\\langle \\cdot \\rangle_{\\text{recon}}$ 分别为数据分布和重构分布的期望。\n",
    "\n",
    "---\n",
    "#### **二、整体模块架构与训练模式**\n",
    "代码实现了基于PyTorch的深度信念网络(DBN)，采用分层架构设计，支持从无监督预训练到有监督学习的完整流程。\n",
    "\n",
    "- **模块架构**：\n",
    "  -  **DBNPretrainer**  \n",
    "      - 实现多层RBM的堆叠与逐层无监督预训练，提供特征提取接口。  \n",
    "  -  **AbstractSupervisedDBN**  \n",
    "      - 定义DBN监督学习的通用接口用于支持多模式训练策略，包括预训练、微调、分类器训练与预测等抽象方法。  \n",
    "  -  **AbstractSupervisedDBNClassifier**  \n",
    "      - 基于`AbstractSupervisedDBN`，实现PyTorch下的通用工具方法封装，包括特征提取、分类器集成(逻辑回归，支持向量机以及随机森林等)等。\n",
    "  -  **SupervisedDBNClassification**  \n",
    "      - 具体分类任务实现、微调网络构建以及训练。\n",
    "\n",
    "- **训练模式**：\n",
    "  1. 无监督模式: 仅预训练，用于特征提取\n",
    "  2. 分类器模式: 预训练 + 下游分类器训练\n",
    "  3. 微调网络模式: 预训练 + 网络反向传播微调\n",
    "   \n",
    "---\n",
    "#### **三、核心类功能和接口概述**\n",
    "\n",
    "##### **1. 核心类 `DBNPretrainer（无监督预训练DBN）`**\n",
    "- **关键参数**：\n",
    "  - `hidden_layers_structure`：隐层单元数（默认两层[100, 100]）\n",
    "  - `learning_rate_rbm`：RBM学习率（默认0.1）\n",
    "  - `n_epochs_rbm`：每层RBM训练轮数（默认10）\n",
    "  - `batch_size`：批大小（默认100）\n",
    "  - `verbose`：打印训练信息（默认True）\n",
    "  - `shuffle`：数据打乱（默认True）\n",
    "  - `drop_last`：是否丢弃最后不足batch的样本（默认False）\n",
    "  - `random_state`：随机种子\n",
    "- **设备支持**：自动选择GPU（`cuda`）或CPU\n",
    "- **核心方法**\n",
    "  - **创建RBM层 (`create_rbm_layer` 方法)**\n",
    "    - **初始化RBM**：使用 `RestrictedBoltzmannMachine` 定义可见层与隐层维度。\n",
    "  - **单批次训练步骤 (`_train_batch` 方法)**\n",
    "    1. **正相（Positive Phase）**：计算隐层激活概率 $ P(\\mathbf{h}|\\mathbf{v}) $。\n",
    "    2. **负相（Negative Phase）**：通过模拟退火采样器（`SimulatedAnnealingOptimizer`）生成重构样本。\n",
    "    3. **目标函数**：最小化能量函数加权重衰减（L2正则化）。\n",
    "    4. **反向传播**：更新权重和偏置。\n",
    "  - **单层RBM训练 (`_train_rbm_layer` 方法)**\n",
    "      - **初始化优化器**：采用随机梯度下降（SGD）优化参数。\n",
    "      - **DataLoader处理批量数据**\n",
    "  - **预训练堆叠RBM (`fit` 方法)**\n",
    "  - **特征变换，逐层提取特征 (`transform` 方法)**\n",
    "##### **2. 核心类 `AbstractSupervisedDBN（抽象接口定义）`**\n",
    "- **关键参数**：\n",
    "  - `fine_tuning`：模式选择（默认False）\n",
    "  - `learning_rate`：微调学习率（默认0.1）\n",
    "  - `n_iter_backprop`：反向传播迭代次数（默认100）\n",
    "  - `l2_regularization`：L2正则化（默认1e-4）\n",
    "  - `activation_function`：激活函数（默认'sigmoid'）\n",
    "  - `dropout_p`：Dropout概率（默认0.0）\n",
    "##### **3. 核心类 `AbstractSupervisedDBNClassifier（分类器模式具体实现，以及微调网络构建工具）`**\n",
    "- **关键参数**：\n",
    "  - `classifier_type`：支持多种分类器（默认逻辑回归）\n",
    "  - `clf_C`：正则化强度（默认1.0）\n",
    "  - `clf_iter`：迭代次数（默认100）\n",
    "##### **4. 核心类 `SupervisedDBNClassification（具体分类实现）`**\n",
    "- **微调网络构建**：使用预训练的权重来初始化(默认两层RBM，以及无Dropout层)\n",
    "  - 网络结构：输入层 → [线性层 + 激活函数 + Dropout] × N → 输出层\n",
    "  - 线性层：使用对应的RBM的权重初始化\n",
    "  - 输出层：随机初始化，在微调阶段学习\n",
    "\n",
    "- **训练策略**：\n",
    "  - 使用预训练权重初始化\n",
    "  - CrossEntropyLoss损失函数\n",
    "  - SGD优化器 + L2正则化\n",
    "  - 支持Dropout防止过拟合\n",
    "\n",
    "##### **5. 其他内容**\n",
    "\n",
    "- **数据加载 (`load_data` 方法)**\n",
    "\n",
    "    - 数据集：使用 `sklearn.datasets.load_digits`（8x8手写数字图像）。\n",
    "    - 增强：对原始图像进行上下左右平移，扩展数据集。\n",
    "\n",
    "- **训练过程可视化 (`_visualize_training_progress` 方法, 设置`plot_img=True`)**\n",
    "\n",
    "    - 权重与梯度：实时监控权重矩阵及其梯度变化。\n",
    "    - 生成样本：实时展示模型\"生成\"新样本的能力\n",
    "    - 重建样本：可视化重建误差的演变\n",
    "\n",
    "- **结果可视化 (`RBMVisualizer`类)**\n",
    "\n",
    "    - 训练后RBM权重可视化\n",
    "    - 分类任务结果: 混淆矩阵可视化\n",
    "    - 重建样本：训练完成后对测试图像进行编码-解码得到的重建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f0e9dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "seed = 42\n",
    "# PyTorch\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)       # 为当前GPU设置\n",
    "    torch.cuda.manual_seed_all(seed)   # 为所有GPU设置\n",
    "# Python\n",
    "random.seed(seed)\n",
    "# NumPy\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bfdf9c-b6f5-41e8-8891-722220c7cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supervised_dbn_digits import load_data, RBMVisualizer, SupervisedDBNClassification\n",
    "\n",
    "def save_network_structure(dbn, filename_prefix):\n",
    "    \"\"\"保存网络结构信息到文件\"\"\"\n",
    "    structure = dbn.get_network_structure()\n",
    "    \n",
    "    # 保存为JSON\n",
    "    import json\n",
    "    with open(f\"results/{filename_prefix}_structure.json\", 'w') as f:\n",
    "        json.dump(structure, f, indent=2)\n",
    "    \n",
    "    # 保存为文本摘要\n",
    "    with open(f\"results/{filename_prefix}_summary.txt\", 'w') as f:\n",
    "        f.write(\"DBN Model Summary\\n\")\n",
    "        f.write(\"=================\\n\\n\")\n",
    "        f.write(f\"Pre-train layers: {structure['pretrain_layers']}\\n\")\n",
    "        f.write(f\"Fine-tune layers: {structure['fine_tune_layers']}\\n\")\n",
    "        f.write(f\"Hidden units: {structure['hidden_units']}\\n\")\n",
    "        f.write(f\"Number of classes: {structure['num_classes']}\\n\")\n",
    "        f.write(f\"Training mode: {structure['mode']}\\n\")\n",
    "    \n",
    "    print(f\"Network structure saved to results/{filename_prefix}_*\")\n",
    "\n",
    "def demonstrate_both_modes():\n",
    "    \"\"\"演示两种模式的使用\"\"\"\n",
    "    # 加载数据\n",
    "    X_train, X_test, y_train, y_test = load_data(plot_img=False)\n",
    "    \n",
    "    # 模式1: 使用微调网络\n",
    "    print(\"=== Mode 1: Fine-tuning Network ===\")\n",
    "    dbn_fine_tune = SupervisedDBNClassification(\n",
    "        hidden_layers_structure=[128, 256],\n",
    "        learning_rate_rbm=0.1,\n",
    "        n_epochs_rbm=2,\n",
    "        batch_size=64,\n",
    "        fine_tuning=True,  # 启用微调\n",
    "        learning_rate=0.1,\n",
    "        n_iter_backprop=100,\n",
    "        l2_regularization=1e-4,\n",
    "        activation_function='sigmoid',\n",
    "        verbose=True,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # 训练模型\n",
    "    dbn_fine_tune.fit(X_train, y_train)\n",
    "\n",
    "    # 评估模型\n",
    "    acc = dbn_fine_tune.score(X_test, y_test)*100\n",
    "    print(f\"Fine-tuning network testing accuracy: {acc:.2f}%\")\n",
    "\n",
    "    # 获取训练后的网络结构信息\n",
    "    structure_info = dbn_fine_tune.get_network_structure()\n",
    "    print(\"\\n=== Trained Network Structure ===\")\n",
    "    for key, value in structure_info.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    # 保存网络结构信息\n",
    "    save_network_structure(dbn_fine_tune, \"fine_tune_analysis\")\n",
    "    \n",
    "    # 模式2: 使用下游分类器\n",
    "    print(\"\\n=== Mode 2: Pipline Classifier ===\")\n",
    "    dbn_classifier = SupervisedDBNClassification(\n",
    "        hidden_layers_structure=[128],\n",
    "        learning_rate_rbm=0.1,\n",
    "        n_epochs_rbm=2,\n",
    "        batch_size=64,\n",
    "        fine_tuning=False,  # 使用分类器\n",
    "        # 选项: logistic, svm, random_forest\n",
    "        classifier_type = 'logistic', \n",
    "        clf_C=500,\n",
    "        clf_iter=1000,\n",
    "        verbose=True,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # 训练模型\n",
    "    dbn_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # 评估模型\n",
    "    acc2 = dbn_classifier.score(X_test, y_test)*100\n",
    "    print(f\"Classifier testing accuracy: {acc2:.2f}%\")\n",
    "\n",
    "    # 获取训练后的网络结构信息\n",
    "    structure_info = dbn_classifier.get_network_structure()\n",
    "    print(\"\\n=== Trained Network Structure ===\")\n",
    "    for key, value in structure_info.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    # 保存网络结构信息\n",
    "    save_network_structure(dbn_classifier, \"classifier_analysis\") \n",
    "    \n",
    "    # 特征提取示例\n",
    "    print(\"\\n=== Feature Extraction ===\")\n",
    "    features = dbn_classifier.transform(X_test)\n",
    "    print(f\"Original shape: {X_test.shape}\")\n",
    "    print(f\"Feature shape: {features.shape}\")\n",
    "    \n",
    "    return dbn_fine_tune, dbn_classifier\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model1, model2 = demonstrate_both_modes()\n",
    "    \n",
    "    # 保存模型参数\n",
    "    print(\"\\n=== Save Parameters ===\")\n",
    "    model1.save_parameters(file_prefix=\"fine_tune\")\n",
    "    model2.save_parameters(file_prefix=\"classifier\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21841a98-0736-4d75-9e68-20ad3f234398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8fc9c2-f338-406d-b6ad-22e9b343ea9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
