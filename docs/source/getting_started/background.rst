========
预备知识
========

本章介绍使用 Kaiwu-PyTorch-Plugin 所需的背景知识，包括神经网络的发展、玻尔兹曼机的基本概念，以及量子计算如何加速玻尔兹曼机的训练。

1. 神经网络发展
---------------

神经网络作为人工智能领域的核心工具，主要有两个重要分支：

前馈神经网络
^^^^^^^^^^^^

前馈神经网络强调信息单向逐层计算，是目前最广泛使用的神经网络架构：

- **多层感知机（MLP）**：模仿生物神经元层级传递信号的网络结构，通过非线性激活函数学习复杂映射
- **卷积神经网络（CNN）**：擅长捕捉空间特征，广泛应用于图像处理
- **循环神经网络（RNN）**：专门处理序列依赖关系，适用于时间序列和自然语言处理
- **Transformer（2017年）**：凭借自注意力机制结合大规模并行计算能力，成为当下大语言模型的主流架构

能量神经网络
^^^^^^^^^^^^

能量神经网络受物理学启发，强调系统通过演化向能量最低的稳定态收敛：

- **伊辛（Ising）模型**：源于统计物理学，描述磁体中原子自旋的相互作用
- **Hopfield 网络（1982年）**：通过定义"能量函数"使网络状态收敛到能量最低的稳定态，实现联想记忆功能
- **玻尔兹曼机（BM）**：引入概率采样模拟更复杂的能量分布，是人工智能领域最贴近"思考"的模型之一

最新突破
^^^^^^^^

**基于能量的 Transformer（EBTs）** 将能量网络模型（EBMs）与 Transformer 结合：

- 在多模态训练中的扩展速率比主流 Transformer 提升 35%
- 性能提高 29%
- 为能量神经网络模型的研究开辟了新方向

2. 玻尔兹曼机基础
-----------------

什么是玻尔兹曼机
^^^^^^^^^^^^^^^^

玻尔兹曼机（Boltzmann Machine，简称 BM）是一种基于统计物理学的机器学习模型，由 2024 年诺贝尔物理学奖获得者 Geoffrey Hinton 提出。它通过模拟系统能量最小化来训练网络，从而能够识别数据中的特定元素特征。

玻尔兹曼机通常具有以下性质：

1. **二值化**：每个神经单元的状态值只有 0 和 1
2. **双层结构**：由可见层和隐藏层构成
3. **全连接**：层间和层内单元之间是全连接，且每两个单元之间的互相影响是对称的

因为能够学习输入数据的内在结构和概率分布，从而生成新的、与训练数据相似的数据样本，玻尔兹曼机被称为人工智能领域最贴近"思考"的模型之一。

玻尔兹曼分布
^^^^^^^^^^^^

玻尔兹曼分布是统计物理的基石之一，描述粒子处于特定状态下的概率，是关于状态能量与系统温度的函数。能量越低的状态，其出现的概率越高。

玻尔兹曼机通过一个能量函数来定义网络节点状态的概率，该概率分布遵循玻尔兹曼分布：

.. math::

    P(\mathbf{s}) = \frac{1}{Z} e^{-E(\mathbf{s})/T}

其中：

- :math:`P(\mathbf{s})` 是状态 :math:`\mathbf{s}` 的概率
- :math:`E(\mathbf{s})` 是状态 :math:`\mathbf{s}` 的能量
- :math:`T` 是温度参数
- :math:`Z` 是配分函数（归一化常数）

吉布斯采样
^^^^^^^^^^

玻尔兹曼机采用基于吉布斯采样（Gibbs Sampling）的样本生成方法来进行训练，通过持续调整网络里的单元状态，慢慢逼近玻尔兹曼机的真实概率分布。

在进行吉布斯采样时，固定的温度下运行足够时间后，玻尔兹曼机会达到热平衡状态，此时任何全局状态的概率都服从玻尔兹曼分布。

**对比散度（CD）算法** 是吉布斯采样的变体，一般用于受限玻尔兹曼机的训练中，只需运行 K 次吉布斯采样即可，故对比散度算法又称作 K 步吉布斯采样法。

受限玻尔兹曼机
^^^^^^^^^^^^^^

在实际应用中，使用较为广泛的是基于玻尔兹曼机的改造版本——**受限玻尔兹曼机（Restricted Boltzmann Machine, RBM）**。

.. list-table:: 玻尔兹曼机 vs 受限玻尔兹曼机
   :widths: 20 40 40
   :header-rows: 1

   * - 特性
     - 玻尔兹曼机（BM）
     - 受限玻尔兹曼机（RBM）
   * - 层内连接
     - 层内单元全连接
     - 层内单元相互独立，无连接
   * - 层间连接
     - 全连接
     - 全连接
   * - 采样方式
     - 顺序采样
     - 可并行采样所有可见层或隐藏层单元
   * - 训练效率
     - 较低
     - 较高，更快达到热平衡

受限玻尔兹曼机的"受限"体现在层内单元相互独立，这使得吉布斯采样可以在一个步骤内并行更新所有隐藏单元或所有可见单元，大大提高了采样效率。

玻尔兹曼机的训练
^^^^^^^^^^^^^^^^

玻尔兹曼机训练过程的核心是通过对比散度等算法，让模型学习数据的概率分布，最小化两者间的差异。训练过程包含以下步骤：

**（1）正相阶段（数据分布下的统计量）**

- 根据训练样本固定可见单元
- 计算隐藏单元的条件概率，采样隐藏单元状态

**（2）负相阶段（模型分布下的统计量）**

通过吉布斯采样从模型分布中生成样本，模拟"重构"过程：

- 从隐藏单元重构可见单元
- 重复若干次上述吉布斯采样过程，逐渐逼近玻尔兹曼分布

**（3）参数更新**

根据正相和负相统计量的差异，按梯度下降方向更新参数，从而缩小两者的差距，直至参数收敛。

3. 量子计算与玻尔兹曼机
-----------------------

经典方法的挑战
^^^^^^^^^^^^^^

玻尔兹曼机的训练需要不断从复杂的玻尔兹曼分布中采样。因其全连接结构，采样过程中其配分函数（所有可能状态的玻尔兹曼权重之和）计算困难，难以精确计算概率分布，导致：

- **训练效率低下**：采样过程耗时
- **计算复杂度极高**：复杂度随神经元数量呈指数级增长
- **NP-hard 问题**：本质上是一个 NP-hard 问题

相干光量子计算机（CIM）
^^^^^^^^^^^^^^^^^^^^^^^

**相干伊辛机（Coherent Ising Machine, CIM）** 是一种利用光量子搭建物理 Ising 模型的量子计算机：

- 利用光量子的相干特性构建物理系统
- 凭借量子并行特性高效处理玻尔兹曼分布采样
- 光量子比特间天然全连接，无需额外拓扑映射

量子优势
^^^^^^^^

由于 Ising 模型与玻尔兹曼机能够互相映射，利用量子计算可以解决经典玻尔兹曼机因高复杂度而无法高效训练的难点：

.. list-table::
   :widths: 30 35 35
   :header-rows: 1

   * - 对比项
     - 经典计算
     - 量子计算（CIM）
   * - 采样效率
     - 随神经元数量指数增长
     - 量子并行，显著加速
   * - 网络规模
     - 受限于计算复杂度
     - 支持大规模网络
   * - 连接拓扑
     - 需要额外映射
     - 天然全连接
   * - 运行时间
     - 长时间迭代
     - 快速收敛

**Kaiwu-PyTorch-Plugin 正是这一优势的体现**，它将相干光量子计算机的采样能力与 PyTorch 的灵活性相结合，为能量神经网络的训练提供了强大的工具支持。

4. PyTorch 简介
---------------

PyTorch 是一个由 Meta 开发的基于 Python 的开源深度学习框架，主要用于机器学习和深度学习的科研与应用开发，以其灵活性、动态计算图和强大的 GPU 加速能力著称。

主要特点
^^^^^^^^

- **动态计算图**：采用反向模式自动微分技术，类比一台磁带录音机，录制完成后进行回放，进而计算梯度
- **调试友好**：动态图使得调试相对简单，能够很好地适应诸如动态神经网络等应用程序
- **生态丰富**：拥有大量预训练模型、工具库和社区支持
- **GPU 加速**：原生支持 CUDA，可轻松实现 GPU 加速

Kaiwu-PyTorch-Plugin 继承了 PyTorch 的这些优势，使得用户可以在熟悉的 PyTorch 环境中使用量子计算能力。
